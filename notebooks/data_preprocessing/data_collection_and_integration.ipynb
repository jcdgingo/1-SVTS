{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Go up two directories to get the project root\n",
    "project_root = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Add the project root to sys.path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.utils import data_source\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "Type of sentiment_data: <class 'pandas.core.frame.DataFrame'>\n",
      "Content of sentiment_data:       ticker relevance_score ticker_sentiment_score ticker_sentiment_label  \\\n",
      "0  FOREX:USD        0.149966               0.018743                Neutral   \n",
      "1  FOREX:USD         0.06515               0.024153                Neutral   \n",
      "2  FOREX:USD        0.246404               0.173937       Somewhat-Bullish   \n",
      "3  FOREX:USD        0.075397               0.041496                Neutral   \n",
      "4  FOREX:USD        0.269776               0.044056                Neutral   \n",
      "\n",
      "  time_published(est)  \n",
      "0    2023-09-18 19:16  \n",
      "1    2023-09-18 20:28  \n",
      "2    2023-09-18 20:30  \n",
      "3    2023-09-18 22:00  \n",
      "4    2023-09-18 22:26  \n",
      "Updated last_date to: 20231004T0820\n",
      "Starting iteration 1\n",
      "Type of sentiment_data: <class 'pandas.core.frame.DataFrame'>\n",
      "Content of sentiment_data:       ticker relevance_score ticker_sentiment_score ticker_sentiment_label  \\\n",
      "0  FOREX:USD        0.324139               0.121448                Neutral   \n",
      "1  FOREX:USD        0.118647               0.011514                Neutral   \n",
      "2  FOREX:USD         0.05833              -0.034094                Neutral   \n",
      "3  FOREX:USD        0.201803              -0.249534       Somewhat-Bearish   \n",
      "4  FOREX:USD        0.244109                    0.0                Neutral   \n",
      "\n",
      "  time_published(est)  \n",
      "0    2023-10-04 04:27  \n",
      "1    2023-10-04 04:54  \n",
      "2    2023-10-04 05:13  \n",
      "3    2023-10-04 05:41  \n",
      "4    2023-10-04 05:43  \n",
      "Updated last_date to: 20231020T0237\n",
      "Starting iteration 2\n",
      "Type of sentiment_data: <class 'pandas.core.frame.DataFrame'>\n",
      "Content of sentiment_data:       ticker relevance_score ticker_sentiment_score ticker_sentiment_label  \\\n",
      "0  FOREX:USD        0.065327                    0.0                Neutral   \n",
      "1  FOREX:USD        0.055621              -0.066989                Neutral   \n",
      "2  FOREX:USD         0.02415              -0.026529                Neutral   \n",
      "3  FOREX:USD          0.0428               0.041597                Neutral   \n",
      "4  FOREX:USD        0.204072                    0.0                Neutral   \n",
      "\n",
      "  time_published(est)  \n",
      "0    2023-10-19 23:02  \n",
      "1    2023-10-19 23:14  \n",
      "2    2023-10-20 00:00  \n",
      "3    2023-10-20 00:00  \n",
      "4    2023-10-20 00:13  \n",
      "Updated last_date to: 20231023T1749\n",
      "Starting iteration 3\n",
      "Type of sentiment_data: <class 'pandas.core.frame.DataFrame'>\n",
      "Content of sentiment_data:       ticker relevance_score ticker_sentiment_score ticker_sentiment_label  \\\n",
      "0  FOREX:USD        0.020668               0.035582                Neutral   \n",
      "1  FOREX:USD         0.33628              -0.246664       Somewhat-Bearish   \n",
      "2  FOREX:USD        0.082251               0.031212                Neutral   \n",
      "3  FOREX:USD        0.262522               0.159969       Somewhat-Bullish   \n",
      "4  FOREX:USD        0.208017               0.167197       Somewhat-Bullish   \n",
      "\n",
      "  time_published(est)  \n",
      "0    2023-10-23 14:06  \n",
      "1    2023-10-23 14:21  \n",
      "2    2023-10-23 14:35  \n",
      "3    2023-10-23 15:16  \n",
      "4    2023-10-23 16:00  \n",
      "Updated last_date to: 20231023T1749\n",
      "Starting iteration 4\n",
      "Type of sentiment_data: <class 'pandas.core.frame.DataFrame'>\n",
      "Content of sentiment_data:       ticker relevance_score ticker_sentiment_score ticker_sentiment_label  \\\n",
      "0  FOREX:USD        0.020668               0.035582                Neutral   \n",
      "1  FOREX:USD         0.33628              -0.246664       Somewhat-Bearish   \n",
      "2  FOREX:USD        0.082251               0.031212                Neutral   \n",
      "3  FOREX:USD        0.262522               0.159969       Somewhat-Bullish   \n",
      "4  FOREX:USD        0.208017               0.167197       Somewhat-Bullish   \n",
      "\n",
      "  time_published(est)  \n",
      "0    2023-10-23 14:06  \n",
      "1    2023-10-23 14:21  \n",
      "2    2023-10-23 14:35  \n",
      "3    2023-10-23 15:16  \n",
      "4    2023-10-23 16:00  \n",
      "Updated last_date to: 20231023T1749\n",
      "Starting iteration 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jessi\\OneDrive\\1 Projects\\1-svts\\notebooks\\data_preprocessing\\data_collection_and_integration.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jessi/OneDrive/1%20Projects/1-svts/notebooks/data_preprocessing/data_collection_and_integration.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Fetch data from the specified date\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jessi/OneDrive/1%20Projects/1-svts/notebooks/data_preprocessing/data_collection_and_integration.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m data_collector\u001b[39m.\u001b[39mdate_from \u001b[39m=\u001b[39m last_date\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jessi/OneDrive/1%20Projects/1-svts/notebooks/data_preprocessing/data_collection_and_integration.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m sentiment_data \u001b[39m=\u001b[39m data_collector\u001b[39m.\u001b[39;49mfetch_news_sentiment_data()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jessi/OneDrive/1%20Projects/1-svts/notebooks/data_preprocessing/data_collection_and_integration.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Log and print the type and content of sentiment_data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jessi/OneDrive/1%20Projects/1-svts/notebooks/data_preprocessing/data_collection_and_integration.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m logging\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mType of sentiment_data: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(sentiment_data)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jessi\\OneDrive\\1 Projects\\1-svts\\src\\utils\\data_source.py:26\u001b[0m, in \u001b[0;36mFinancialAnalytics.fetch_news_sentiment_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[0;32m     25\u001b[0m eur_news_data \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n\u001b[1;32m---> 26\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(eur_news_data)\n\u001b[0;32m     27\u001b[0m nested_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mjson_normalize(df[\u001b[39m'\u001b[39m\u001b[39mfeed\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m filtered_data \u001b[39m=\u001b[39m nested_df[\u001b[39m'\u001b[39m\u001b[39mticker_sentiment\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39many\u001b[39m(item\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mticker\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mticker \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m x))\n",
      "File \u001b[1;32mc:\\Users\\jessi\\OneDrive\\1 Projects\\1-svts\\python-venv\\Lib\\site-packages\\pandas\\core\\frame.py:736\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    730\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    731\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    732\u001b[0m     )\n\u001b[0;32m    734\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    735\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    737\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    738\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\jessi\\OneDrive\\1 Projects\\1-svts\\python-venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\jessi\\OneDrive\\1 Projects\\1-svts\\python-venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\jessi\\OneDrive\\1 Projects\\1-svts\\python-venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m indexes \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 667\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf using all scalar values, you must pass an index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    669\u001b[0m \u001b[39mif\u001b[39;00m have_series:\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='debug.log', level=logging.DEBUG)\n",
    "\n",
    "ticker = 'FOREX:USD'\n",
    "initial_date = '20230918T2243'\n",
    "sort = 'EARLIEST'\n",
    "file_path = None\n",
    "\n",
    "data_collector = data_source.FinancialAnalytics(file_path=file_path, ticker=ticker, date_from=initial_date, sort=sort)\n",
    "last_date = initial_date\n",
    "all_data = []\n",
    "\n",
    "iteration_count = 0  # To keep track of the number of iterations\n",
    "\n",
    "while True:\n",
    "    logging.debug(f\"Starting iteration {iteration_count}\")\n",
    "    print(f\"Starting iteration {iteration_count}\")\n",
    "\n",
    "    # Fetch data from the specified date\n",
    "    data_collector.date_from = last_date\n",
    "    sentiment_data = data_collector.fetch_news_sentiment_data()\n",
    "\n",
    "    # Log and print the type and content of sentiment_data\n",
    "    logging.debug(f\"Type of sentiment_data: {type(sentiment_data)}\")\n",
    "    logging.debug(f\"Content of sentiment_data: {sentiment_data.head()}\")\n",
    "    print(f\"Type of sentiment_data: {type(sentiment_data)}\")\n",
    "    print(f\"Content of sentiment_data: {sentiment_data.head()}\")\n",
    "\n",
    "    # If no data is retrieved, break\n",
    "    if sentiment_data.empty:\n",
    "        logging.debug(\"Breaking loop, sentiment_data is empty.\")\n",
    "        print(\"Breaking loop, sentiment_data is empty.\")\n",
    "        break\n",
    "\n",
    "    # Append the fetched data to the all_data list\n",
    "    all_data.append(sentiment_data)\n",
    "\n",
    "    # Update the last_date based on the last timestamp of the fetched data\n",
    "    sentiment_data['time_published(est)'] = sentiment_data['time_published(est)'].str.replace('-', '').str.replace(' ', 'T').str.replace(':', '')\n",
    "    last_date = sentiment_data['time_published(est)'].iloc[-1]\n",
    "    logging.debug(f\"Updated last_date to: {last_date}\")\n",
    "    print(f\"Updated last_date to: {last_date}\")\n",
    "\n",
    "    iteration_count += 1\n",
    "\n",
    "# Combine all fetched data\n",
    "combined_data = pd.concat(all_data, ignore_index=True)\n",
    "combined_data = combined_data.drop_duplicates()\n",
    "\n",
    "logging.debug(\"Data collection completed.\")\n",
    "print(\"Data collection completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat(all_data, ignore_index=True)\n",
    "combined_data = combined_data.drop_duplicates()\n",
    "combined_data.to_csv(r'C:\\Users\\jessi\\OneDrive\\1 Projects\\1-svts\\data\\external\\news-analysis\\usd_sentiment7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = r\"C:\\Users\\jessi\\OneDrive\\1 Projects\\1-svts\\data\\external\\news-analysis\"\n",
    "\n",
    "# List of CSV filenames\n",
    "files = [\n",
    "    os.path.join(directory, \"usd_sentiment.csv\"),\n",
    "    os.path.join(directory, \"usd_sentiment1.csv\"),\n",
    "    os.path.join(directory, \"usd_sentiment2.csv\"),\n",
    "    os.path.join(directory, \"usd_sentiment3.csv\"),\n",
    "    os.path.join(directory, \"usd_sentiment4.csv\"),\n",
    "    os.path.join(directory, \"usd_sentiment5.csv\"),\n",
    "    os.path.join(directory, \"usd_sentiment6.csv\"),\n",
    "    os.path.join(directory, \"usd_sentiment7.csv\")\n",
    "]\n",
    "\n",
    "# Read and combine all files into one DataFrame\n",
    "all_data = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "all_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Define your target folder\n",
    "\n",
    "# Ensure the folder exists, if not, create it\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Get the timestamp of the last data entry\n",
    "last_timestamp = all_data['time_published(est)'].iloc[-1]\n",
    "\n",
    "# Format the timestamp for filename \n",
    "formatted_timestamp = last_timestamp.replace(' ', '_').replace(':', '-').replace('/', '-')\n",
    "\n",
    "# Construct the new filename with path included\n",
    "new_filename = os.path.join(directory, f\"usd_sentiment_combined_{formatted_timestamp}.csv\")\n",
    "\n",
    "# Save the combined data to the new filename\n",
    "all_data.to_csv(new_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT5 data collection 1 minute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
